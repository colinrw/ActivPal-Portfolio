# Training a model

### Introduction

Training is model is an essential part of every Machine Learning model. It is important to find the correct balance to prevent overfitting or underfitting. 

Explanation of Hyperparameter tuning for the Random Forest and XGBoost model can be found [here](configuring_a_model.md).

<details><summary>Prevention of Under/Over fitting</summary>

Throughout the implementation of the MET prediction model we've encountered multiple obstacles. 

<details><summary>Removing Irrelevent Features</summary>

text

</details>

<details><summary>Creating Relevent Features</summary>

text

</details>

<details><summary>Removing Noise </summary>

The noise for the MET prediction models were usually respondents who weren't able to perform the lab activities according to the rest of the respondents. For example: 70+ year old respondents that could not complete the activities for the given time were excluded from the experiment. This has been agreed in consulation with Annemieke van Leuten and John Bolte from Centraal Bureau of Statistiek (CBS). 

</details>

---

</details>

<details><summary>First Run Training</summary>

text

</details>

---

<details><summary>Cross Validation Training</summary>

text

</details>

---

<details><summary>Applying Test Dataset</summary>

text

</details>

---

[<  Configuring a model](configuring_a_model.md) â€” [Evaluating a model >](evaluating_a_model.md) 